{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d46a77-e8c9-4c58-8d63-e12b7a105bd0",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f15a84-b3bb-42a0-abe8-d17632d11bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import math\n",
    "from math import ceil\n",
    "import cv2\n",
    "from typing import Optional, Literal, Tuple, List\n",
    "import pyarrow as pa, pyarrow.parquet as pq\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf074e98-163b-40a6-b931-f4f09d6573b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printed Size : 1733904\n",
      "Handwritten Size : 6482\n"
     ]
    }
   ],
   "source": [
    "# ----- Load Full Dataset -----\n",
    "data = pd.read_parquet(r\"data\\raw_data\\train_raw.parquet\")\n",
    "\n",
    "# ----- Split By Source -----\n",
    "printed = data[data[\"source\"] == \"printed\"]\n",
    "written = data[data[\"source\"] == \"handwritten\"]\n",
    "\n",
    "# ----- Pre-sampling size -----\n",
    "print(\"Printed Size :\", len(printed))\n",
    "print(\"Handwritten Size :\", len(written))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753674ce-417d-4dd6-8ff6-0cf39877996b",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1fbea1-efb8-49a7-8b1d-df71e34566f8",
   "metadata": {},
   "source": [
    "Based on exploratory data analysis performed on this dataset, we will perform the fillowing preprocessing techniques:\n",
    "- Downsampling (printed data)\n",
    "- Conversion to Grayscale\n",
    "- Resizing to Fixed Dimensions\n",
    "- Noise Removal (conditional)\n",
    "- Binarization (conditional)\n",
    "- Normalization\n",
    "- Padding and Alignment\n",
    "- Augmentation (handwritten data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f3bb6-5fc8-4f38-99c4-a1649f3c96c0",
   "metadata": {},
   "source": [
    "### Down Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0ad34-2649-4d48-9769-988ad6bc2edd",
   "metadata": {},
   "source": [
    "We will down-sample printed and data to 100_000 samples, and augment handwritten data to increase size to 100_000. This will fix the issue of class imbalance while prserving enough data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595d9e93-f811-4c35-9622-4adf5c1a622c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handwritten Size post-sampling: 100000\n"
     ]
    }
   ],
   "source": [
    "# ----- Downsample Printed Data -----\n",
    "printed = printed.sample(n = 100000, random_state=42)\n",
    "\n",
    "# ----- Post-sampling size -----\n",
    "print(\"Handwritten Size post-sampling:\", len(printed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371bc7c5-a2ab-4602-91aa-8d1e32176723",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b6af1f-a7bb-4cfc-800d-602023f40c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Obtain Raw Bytes -----\n",
    "def get_bytes(x) -> bytes:\n",
    "    if isinstance(x, dict) and \"bytes\" in x:\n",
    "        v = x[\"bytes\"]\n",
    "        if isinstance(v, (bytes, bytearray, memoryview)):\n",
    "            return bytes(v)\n",
    "    if isinstance(x, (bytes, bytearray, memoryview)):\n",
    "        return bytes(x)\n",
    "    raise TypeError(\"Image field must be bytes or dict containing key 'bytes' with bytes\")\n",
    "\n",
    "# ----- Decode Compressed Image Bytes -----\n",
    "def decode_image_cv2(image_bytes: bytes) -> np.ndarray:\n",
    "    buf = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(buf, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Failed to decode image bytes\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0049d3c7-e902-4da0-a24b-04e10adc4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Convert to Grayscale -----\n",
    "def to_grayscale(img: np.ndarray) -> np.ndarray:\n",
    "    if img.ndim == 2:\n",
    "        return img\n",
    "    if img.ndim == 3:\n",
    "        if img.shape[2] == 3:\n",
    "            return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img.shape[2] == 4:\n",
    "            return cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
    "        \n",
    "    # ----- Fallback -----\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857ef9df-343a-4518-8162-df9fe56dd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Resize to Consistent Height -----\n",
    "def resize_to_fixed_height(gray: np.ndarray, target_h: int = 128) -> np.ndarray:\n",
    "    h, w = gray.shape[:2]\n",
    "    if h == target_h:\n",
    "        return gray\n",
    "        \n",
    "    scale = target_h / float(h)\n",
    "    new_w = max(1, int(round(w * scale)))\n",
    "    method = cv2.INTER_AREA if target_h < h else cv2.INTER_LINEAR\n",
    "    \n",
    "    return cv2.resize(gray, (new_w, target_h), interpolation=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b90be4-cb5a-4a99-8655-fb7fdc4bd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Noise Removal -----\n",
    "def denoise_optional(gray: np.ndarray, method: Optional[Literal[\"median\", \"bilateral\"]] = None) -> np.ndarray:\n",
    "    if method is None:\n",
    "        return gray\n",
    "    if method == \"median\":\n",
    "        return cv2.medianBlur(gray, ksize=3)\n",
    "    if method == \"bilateral\":\n",
    "        return cv2.bilateralFilter(gray, d=5, sigmaColor=20, sigmaSpace=10)\n",
    "        \n",
    "    raise ValueError(\"Unsupported denoise method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c04e8019-ab6a-4204-b01d-fadaf5b84676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Binarization -----\n",
    "def binarize_optional(gray: np.ndarray, method: Optional[Literal[\"adaptive_mean\", \"adaptive_gaussian\"]] = None) -> np.ndarray:\n",
    "    if method is None:\n",
    "        return gray\n",
    "    block_size = 25\n",
    "    C = 10\n",
    "    if method == \"adaptive_mean\":\n",
    "        return cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, C)\n",
    "    if method == \"adaptive_gaussian\":\n",
    "        return cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, C)\n",
    "    \n",
    "    raise ValueError(\"Unsupported binarization method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9ac029-3caa-4ce7-8fd2-44e5bf344ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Normalization -----\n",
    "def normalize_01(img_u8: np.ndarray) -> np.ndarray:\n",
    "    return (img_u8.astype(np.float32) / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de596b4-a89e-4da9-9a21-d2964321d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Padding -----\n",
    "def pad_to_width(img: np.ndarray, target_w: int, pad_value: float = 1.0, align: Literal[\"left\", \"center\"] = \"left\") -> np.ndarray:\n",
    "    h, w = img.shape\n",
    "    \n",
    "    if w == target_w:\n",
    "        return img\n",
    "    if w > target_w:\n",
    "        return img[:, :target_w]\n",
    "\n",
    "    out = np.full((h, target_w), fill_value=pad_value, dtype=img.dtype)\n",
    "    \n",
    "    if align == \"left\":\n",
    "        out[:, :w] = img\n",
    "    elif align == \"center\":\n",
    "        offset = (target_w - w) // 2\n",
    "        out[:, offset:offset + w] = img\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported align\")\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780b657-e5c4-4639-b3cb-18dce7236da7",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deb39433-23ef-4b1a-851e-faa5a2110d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Preprocessing Pipeline For Single Image -----\n",
    "def preprocess_image_bytes(image_bytes: bytes,\n",
    "                           target_h: int = 128,\n",
    "                           denoise: Optional[Literal[\"median\", \"bilateral\"]] = None,\n",
    "                           binarize: Optional[Literal[\"adaptive_mean\", \"adaptive_gaussian\"]] = None,\n",
    "                           pad_width: Optional[int] = None,\n",
    "                           pad_align: Literal[\"left\", \"center\"] = \"left\",\n",
    "                           pad_value: float = 1.0) -> np.ndarray:\n",
    "\n",
    "    img = decode_image_cv2(image_bytes)\n",
    "    gray = to_grayscale(img)\n",
    "    gray = resize_to_fixed_height(gray, target_h=target_h)\n",
    "    gray = denoise_optional(gray, method=denoise)\n",
    "    gray = binarize_optional(gray, method=binarize)\n",
    "    arr = normalize_01(gray)  # float32 [0,1]\n",
    "\n",
    "    if pad_width is not None:\n",
    "        arr = pad_to_width(arr, target_w=pad_width, pad_value=pad_value, align=pad_align)\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be905b9-1b26-4bee-9a6d-98e474e67898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Preprocessing Pipeline For Complete Dataframe -----\n",
    "def preprocess_dataframe(df: pd.DataFrame,\n",
    "                         image_col: str = \"image\",\n",
    "                         label_col: str = \"text\",\n",
    "                         source_col: str = \"source\",\n",
    "                         target_h: int = 128,\n",
    "                         denoise: Optional[str] = None,\n",
    "                         binarize: Optional[str] = None,\n",
    "                         pad_width: Optional[int] = None,\n",
    "                         pad_align: str = \"left\",\n",
    "                         pad_value: float = 1.0) -> Tuple[List[np.ndarray], List[str], List[str]]:\n",
    "\n",
    "    images, labels, sources = [], [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        b = get_bytes(row[image_col])\n",
    "        arr = preprocess_image_bytes(\n",
    "            b,\n",
    "            target_h=target_h,\n",
    "            denoise=denoise,\n",
    "            binarize=binarize,\n",
    "            pad_width=pad_width,\n",
    "            pad_align=pad_align,\n",
    "            pad_value=pad_value,\n",
    "        )\n",
    "        \n",
    "        images.append(arr)\n",
    "        labels.append(row[label_col])\n",
    "        sources.append(row[source_col])\n",
    "        \n",
    "    return images, labels, sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854fd39-0202-4952-b3fa-c79d792cd64c",
   "metadata": {},
   "source": [
    "## Preprocessing Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ed4da-7dff-43d1-a220-292f8ca52598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Define Defaults for Current Dataset -----\n",
    "TARGET_H = 128\n",
    "DENOISE = None       \n",
    "BINARIZE = None         \n",
    "PAD_WIDTH = None        \n",
    "PAD_ALIGN = \"left\"\n",
    "PAD_VALUE = 1.0\n",
    "\n",
    "# ----- Preprocess Printed Dataset -----\n",
    "printed_imgs, printed_labels, printed_sources = preprocess_dataframe(\n",
    "    printed,\n",
    "    image_col=\"image\",\n",
    "    label_col=\"text\",\n",
    "    source_col=\"source\",\n",
    "    target_h=TARGET_H,\n",
    "    denoise=DENOISE,\n",
    "    binarize=BINARIZE,\n",
    "    pad_width=PAD_WIDTH,\n",
    "    pad_align=PAD_ALIGN,\n",
    "    pad_value=PAD_VALUE,\n",
    ")\n",
    "\n",
    "# ----- Preprocess Handwritten Dataset -----\n",
    "hand_imgs, hand_labels, hand_sources = preprocess_dataframe(\n",
    "    written,\n",
    "    image_col=\"image\",\n",
    "    label_col=\"text\",\n",
    "    source_col=\"source\",\n",
    "    target_h=TARGET_H,\n",
    "    denoise=DENOISE,\n",
    "    binarize=BINARIZE,\n",
    "    pad_width=PAD_WIDTH,\n",
    "    pad_align=PAD_ALIGN,\n",
    "    pad_value=PAD_VALUE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e10de-9273-4626-abff-aa7da49a8ebe",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b833b68-f39d-4a20-bee8-c8f258ed1718",
   "metadata": {},
   "source": [
    "### Augmentation and Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c9e6e-13b3-4742-a1e1-e54a86564cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Set Default Range Object -----\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "# ----- Augmentation Size -----\n",
    "TARGET_TOTAL = 100_000\n",
    "\n",
    "# ----- Define Path for Serialization -----\n",
    "OUT_PATH = r\"data\\handwritten_aug.parquet\"\n",
    "\n",
    "# ----- Defaults for Memmory Efficiency -----\n",
    "BATCH_SIZE = 256           \n",
    "ELASTIC_P = 0.6            \n",
    "MAX_WIDTH_FOR_ELASTIC = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7521c37-9af7-4cb8-b75c-0a8ed08a1e08",
   "metadata": {},
   "source": [
    "### Primitive Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476281e-a56b-4390-ac31-8e51c1b036e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Affine Transforms -----\n",
    "def rand_affine(img, rot_deg=12, scale_range=(0.92, 1.08), shear_deg=8, shift_frac=0.06):\n",
    "    h, w = img.shape\n",
    "    angle = rng.uniform(-rot_deg, rot_deg)\n",
    "    scale = rng.uniform(*scale_range)\n",
    "    shear = np.deg2rad(rng.uniform(-shear_deg, shear_deg))\n",
    "    tx = rng.uniform(-shift_frac, shift_frac) * w\n",
    "    ty = rng.uniform(-shift_frac, shift_frac) * h\n",
    "    M_rot = cv2.getRotationMatrix2D((w/2, h/2), angle, scale)\n",
    "    M_shear = np.array([[1, np.tan(shear), 0], [0, 1, 0]], dtype=np.float32)\n",
    "    M = M_shear @ np.vstack([M_rot, [0,0,1]])\n",
    "    M = M[:2, :]\n",
    "    out = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "    T = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)\n",
    "    out = cv2.warpAffine(out, T, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "# ----- Elastic Distortion -----\n",
    "def elastic_distort(img, alpha=12.0, sigma=6.0, max_width_for_elastic=1200):\n",
    "    h, w = img.shape\n",
    "    if w > max_width_for_elastic:\n",
    "        return img\n",
    "    dx = rng.normal(0, sigma, size=(h, w)).astype(np.float32)\n",
    "    dy = rng.normal(0, sigma, size=(h, w)).astype(np.float32)\n",
    "    dx = cv2.GaussianBlur(dx, (0,0), sigmaX=sigma).astype(np.float32) * (alpha / max(h, w))\n",
    "    dy = cv2.GaussianBlur(dy, (0,0), sigmaX=sigma).astype(np.float32) * (alpha / max(h, w))\n",
    "    x = np.arange(w, dtype=np.float32)\n",
    "    y = np.arange(h, dtype=np.float32)\n",
    "    map_x, map_y = np.meshgrid(x, y)\n",
    "    map_x = (map_x + dx).astype(np.float32, copy=False)\n",
    "    map_y = (map_y + dy).astype(np.float32, copy=False)\n",
    "    out = cv2.remap(img, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "# ----- Stroke Variability -----\n",
    "def stroke_variation(img, p=0.6):\n",
    "    if rng.random() >= p:\n",
    "        return img\n",
    "    k = rng.integers(1, 2+1)\n",
    "    kernel = np.ones((k, k), np.uint8)\n",
    "    u8 = np.clip(img*255, 0, 255).astype(np.uint8)\n",
    "    if rng.random() < 0.5:\n",
    "        u8 = cv2.dilate(u8, kernel, iterations=1)\n",
    "    else:\n",
    "        u8 = cv2.erode(u8, kernel, iterations=1)\n",
    "    return (u8.astype(np.float32) / 255.0)\n",
    "\n",
    "# ----- Conditional Introduction of Blur or Noise -----\n",
    "def blur_or_noise(img, p_blur=0.4, p_noise=0.5):\n",
    "    out = img\n",
    "    if rng.random() < p_blur:\n",
    "        k = int(rng.choice([3,5]))\n",
    "        sigma = float(rng.uniform(0.5, 1.2))\n",
    "        out = cv2.GaussianBlur(out, (k,k), sigmaX=sigma)\n",
    "    if rng.random() < p_noise:\n",
    "        sigma = float(rng.uniform(0.005, 0.02))\n",
    "        noise = rng.normal(0, sigma, size=out.shape).astype(np.float32)\n",
    "        out = np.clip(out + noise, 0.0, 1.0)\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "# ----- Brightness and Contrast Variablity -----\n",
    "def brightness_contrast(img, br_range=(-0.06, 0.06), ct_range=(0.92, 1.10)):\n",
    "    beta = float(rng.uniform(*br_range))\n",
    "    alpha = float(rng.uniform(*ct_range))\n",
    "    out = np.clip(img * alpha + beta, 0.0, 1.0)\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "# ----- Per Image Augment -----\n",
    "def augment_once(img, elastic_p=0.6, max_width_for_elastic=1200):\n",
    "    out = img\n",
    "    if rng.random() < 0.9:\n",
    "        out = rand_affine(out)\n",
    "    if rng.random() < elastic_p:\n",
    "        out = elastic_distort(out, max_width_for_elastic=max_width_for_elastic)\n",
    "    out = stroke_variation(out, p=0.6)\n",
    "    out = blur_or_noise(out, p_blur=0.4, p_noise=0.5)\n",
    "    out = brightness_contrast(out)\n",
    "    out = np.clip(out, 0.0, 1.0).astype(np.float32, copy=False)\n",
    "    # Simple legibility guard\n",
    "    m = float(out.mean())\n",
    "    if (m < 0.08 or m > 0.92) and rng.random() < 0.5:\n",
    "        out = brightness_contrast(img, br_range=(-0.03,0.03), ct_range=(0.95,1.05))\n",
    "        out = np.clip(out, 0.0, 1.0).astype(np.float32, copy=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb836b-2ad0-4840-b574-7dacd0c67eff",
   "metadata": {},
   "source": [
    "### Array Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4056562-824c-477d-a025-dea598ba9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Converiosn to Byte Format -----\n",
    "def encode_png_bytes(arr_float01: np.ndarray) -> bytes:\n",
    "    u8 = np.clip(arr_float01 * 255.0, 0, 255).astype(np.uint8)\n",
    "    ok, buf = cv2.imencode(\".png\", u8)\n",
    "    if not ok:\n",
    "        raise ValueError(\"PNG encoding failed\")\n",
    "    return buf.tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf301b-11dc-479f-b78f-d995f81eff49",
   "metadata": {},
   "source": [
    "### Augmentation Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b3e2c-2bfb-4c01-8dcc-48c826319f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Function to Define Augmented Columns -----\n",
    "def build_augmented_columns(base_images, base_labels, \n",
    "                            base_sources,\n",
    "                            target_total: int,\n",
    "                            max_aug_per_image: int = 25,\n",
    "                            batch_size: int = 256,\n",
    "                            elastic_p: float = 0.6,\n",
    "                            max_width_for_elastic: int = 1200):\n",
    "    \n",
    "    col_image, col_text, col_source = [], [], []\n",
    "\n",
    "    p_total = tqdm(total=target_total, desc=\"Augmenting images\", unit=\"img\")\n",
    "\n",
    "    # ----- Seed Batches -----\n",
    "    n = len(base_images)\n",
    "    produced = 0\n",
    "    i = 0\n",
    "    while produced < min(target_total, n):\n",
    "        j = min(i + batch_size, n, target_total)\n",
    "        for a, l, s in zip(base_images[i:j], base_labels[i:j], base_sources[i:j]):\n",
    "            col_image.append(encode_png_bytes(a))\n",
    "            col_text.append(l)\n",
    "            col_source.append(s)\n",
    "        produced += (j - i)\n",
    "        p_total.update(j - i)\n",
    "        i = j\n",
    "        if produced >= target_total:\n",
    "            break\n",
    "\n",
    "    # ----- Augment to TARGET_TOTAL -----\n",
    "    remaining = target_total - produced\n",
    "    if remaining > 0:\n",
    "        from math import ceil\n",
    "        per_image = min(max_aug_per_image, max(1, ceil(remaining / max(1, len(base_images)))))\n",
    "        idx = 0\n",
    "        batch_count = 0\n",
    "        while produced < target_total:\n",
    "            img = base_images[idx]\n",
    "            lab = base_labels[idx]\n",
    "            src = base_sources[idx]\n",
    "            aug = augment_once(img, elastic_p=elastic_p, max_width_for_elastic=max_width_for_elastic)\n",
    "            col_image.append(encode_png_bytes(aug))\n",
    "            col_text.append(lab)\n",
    "            col_source.append(src)\n",
    "\n",
    "            produced += 1\n",
    "            batch_count += 1\n",
    "            p_total.update(1)\n",
    "\n",
    "            if batch_count >= batch_size:\n",
    "                batch_count = 0\n",
    "\n",
    "            idx += 1\n",
    "            if idx >= len(base_images):\n",
    "                idx = 0\n",
    "                per_image -= 1\n",
    "                if per_image <= 0 and produced < target_total:\n",
    "                    per_image = 1\n",
    "\n",
    "    p_total.close()\n",
    "    return col_image, col_text, col_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ea276-22d6-42c5-8ab4-2c6bcfb326d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Save Dataframe to Parquet -----\n",
    "def to_parquet(out_path: str, col_image, col_text, col_source):\n",
    "    total_rows = len(col_image)\n",
    "    p_save = tqdm(total=total_rows, desc=\"Saving to Parquet\", unit=\"row\")\n",
    "    df = pd.DataFrame({\n",
    "        \"image\": col_image,\n",
    "        \"text\": col_text,\n",
    "        \"source\": col_source,\n",
    "    })\n",
    "    p_save.update(total_rows)\n",
    "    df.to_parquet(out_path, index=False) \n",
    "    p_save.close()\n",
    "    return out_path, total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b62a42-1ece-4678-a440-5add13a36903",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_image, col_text, col_source = build_augmented_columns(\n",
    "    base_images=hand_imgs,\n",
    "    base_labels=hand_labels,\n",
    "    base_sources=hand_sources,\n",
    "    target_total=TARGET_TOTAL,          \n",
    "    max_aug_per_image=25,               \n",
    "    batch_size=BATCH_SIZE,              \n",
    "    elastic_p=ELASTIC_P,                \n",
    "    max_width_for_elastic=MAX_WIDTH_FOR_ELASTIC  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f800fc-a150-464f-937c-246c13bf9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Save Augmented Data -----\n",
    "DATA_DIR = r\"C:\\Users\\Shashwat Kumar\\Desktop\\CodeHub\\Projects\\Optical Character Recognition\\data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# ----- Convert to .parquet in Chunks ----- \n",
    "def to_parquet_chunked(path, images, texts, sources, rows_per_group=5000, compression=\"snappy\"):\n",
    "    n = len(images)\n",
    "    writer = None\n",
    "    try:\n",
    "        for i in range(0, n, rows_per_group):\n",
    "            j = min(i + rows_per_group, n)\n",
    "\n",
    "            # Encode only this chunk to PNG bytes\n",
    "            img_bytes = [encode_png_bytes(img) for img in images[i:j]]\n",
    "\n",
    "            df_chunk = pd.DataFrame({\n",
    "                \"image\":  img_bytes,\n",
    "                \"text\":   texts[i:j],\n",
    "                \"source\": sources[i:j],\n",
    "            })\n",
    "            table = pa.Table.from_pandas(df_chunk, preserve_index=False)\n",
    "\n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(path, table.schema, compression=compression)\n",
    "            writer.write_table(table)\n",
    "    finally:\n",
    "        if writer is not None:\n",
    "            writer.close()\n",
    "\n",
    "# ----- Save Handwritten Augmented -----\n",
    "hand_path = os.path.join(DATA_DIR, \"handwritten_aug.parquet\")\n",
    "to_parquet_chunked(hand_path, col_image, col_text, col_source, rows_per_group=5000, compression=\"snappy\")\n",
    "print(\"Saved:\", hand_path, \"rows:\", len(col_image))\n",
    "\n",
    "# ----- Save Printed -----\n",
    "print_path = os.path.join(DATA_DIR, \"printed.parquet\")\n",
    "to_parquet_chunked(print_path, printed_imgs, printed_labels, printed_sources, rows_per_group=5000, compression=\"snappy\")\n",
    "print(\"Saved:\", print_path, \"rows:\", len(printed_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c0083-836c-42e5-8136-d0ddb753f2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_venv",
   "language": "python",
   "name": "ocr_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
