{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3524ec-7b88-46e8-8ad7-8556ec0b8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import io\n",
    "import os\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb37bbce-29c9-4984-a056-06dbe52c21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model path: C:/Users/Shashwat Kumar/Desktop/Labs/Optical Character Recognition/ml_training/output/printed_model/trocr-final-model\n",
      "✅ Data path: C:\\Users\\Shashwat Kumar\\Desktop\\Labs\\Optical Character Recognition\\data\\images\\test_printed.parquet\n",
      "✅ Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# --- 1. Define Your Project Paths ---\n",
    "MODEL_NAME = \"microsoft/trocr-base-printed\"  # The pretrained HF model name\n",
    "\n",
    "# Model directory (based on your screenshot)\n",
    "relative_model_dir = \"../output/printed_model/trocr-final-model\"\n",
    "abs_model_dir = os.path.abspath(relative_model_dir)\n",
    "MODEL_DIR = abs_model_dir.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# ✅ Corrected data directory (you have data/images/)\n",
    "relative_data_dir = \"../../data/images/\"\n",
    "RAW_DATA_DIR = os.path.abspath(relative_data_dir)\n",
    "TEST_PARQUET = \"test_printed.parquet\"  # or 'val_printed.parquet'\n",
    "TEST_DATA_PATH = os.path.join(RAW_DATA_DIR, TEST_PARQUET)\n",
    "\n",
    "# --- 2. Define Your Column Names ---\n",
    "IMAGE_DATA_COLUMN = \"image\"\n",
    "TEXT_LABEL_COLUMN = \"text\"\n",
    "\n",
    "# --- 3. Setup Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 4. Sanity Checks ---\n",
    "print(f\"✅ Model path: {MODEL_DIR}\")\n",
    "print(f\"✅ Data path: {TEST_DATA_PATH}\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    raise FileNotFoundError(f\"❌ Model directory not found: {MODEL_DIR}\")\n",
    "\n",
    "if not os.path.exists(TEST_DATA_PATH):\n",
    "    raise FileNotFoundError(f\"❌ Test data not found: {TEST_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd31402-1088-4be5-b677-7ececb5bad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processor from Hugging Face: microsoft/trocr-base-printed\n",
      "Loading fine-tuned model from: C:/Users/Shashwat Kumar/Desktop/Labs/Optical Character Recognition/ml_training/output/printed_model/trocr-final-model\n",
      "...Model and processor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading processor from Hugging Face: {MODEL_NAME}\")\n",
    "print(f\"Loading fine-tuned model from: {MODEL_DIR}\")\n",
    "\n",
    "try:\n",
    "    # Load the original processor from Hugging Face\n",
    "    processor = TrOCRProcessor.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    # Load our fine-tuned model weights from the local directory\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR)\n",
    "    \n",
    "    # Move the model to your GPU (if available) or CPU\n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"...Model and processor loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load model. Did you unzip the folder correctly?\")\n",
    "    print(e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "995b9882-e565-4a32-a1df-149790959799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from: C:\\Users\\Shashwat Kumar\\Desktop\\Labs\\Optical Character Recognition\\data\\images\\test_printed.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9005398680664c97a63b1be1c10ba516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 297308 total test samples.\n",
      "\n",
      "Standardizing column schemas...\n",
      "  - Renaming 'label' to 'text' in test set.\n",
      "...Test data schema standardized.\n",
      "\n",
      "--- Using a 1000-sample subset for evaluation ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading test data from: {TEST_DATA_PATH}\")\n",
    "try:\n",
    "    test_dataset = load_dataset(\"parquet\", data_files={\"test\": TEST_DATA_PATH}, split=\"test\")\n",
    "    print(f\"Loaded {len(test_dataset)} total test samples.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load test file. Check your path: {TEST_DATA_PATH}\")\n",
    "    print(e)\n",
    "    raise\n",
    "\n",
    "# --- Standardize Column Schemas ---\n",
    "print(\"\\nStandardizing column schemas...\")\n",
    "if TEXT_LABEL_COLUMN not in test_dataset.column_names and 'label' in test_dataset.column_names:\n",
    "    print(\"  - Renaming 'label' to 'text' in test set.\")\n",
    "    test_dataset = test_dataset.rename_column('label', TEXT_LABEL_COLUMN)\n",
    "if 'source' in test_dataset.column_names:\n",
    "    print(\"  - Removing 'source' column from test set for consistency.\")\n",
    "    test_dataset = test_dataset.remove_columns(['source'])\n",
    "\n",
    "print(\"...Test data schema standardized.\")\n",
    "\n",
    "# --- Select a subset for fast evaluation ---\n",
    "TEST_SUBSET_SIZE = 1000\n",
    "if len(test_dataset) > TEST_SUBSET_SIZE:\n",
    "    test_dataset = test_dataset.shuffle(seed=42).select(range(TEST_SUBSET_SIZE))\n",
    "    print(f\"\\n--- Using a {TEST_SUBSET_SIZE}-sample subset for evaluation ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50fed0e6-10ff-46ad-a59b-0c7fbeff7c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined.\n"
     ]
    }
   ],
   "source": [
    "def predict_batch(batch):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset,\n",
    "    processes the images, and generates predictions.\n",
    "    \"\"\"\n",
    "    images_to_process = []\n",
    "    \n",
    "    # 1. Loop through the batch and load images\n",
    "    for image_data in batch[IMAGE_DATA_COLUMN]:\n",
    "        try:\n",
    "            # This logic handles all 3 data types we've seen\n",
    "            if isinstance(image_data, bytes):\n",
    "                image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "            elif isinstance(image_data, dict) and 'bytes' in image_data:\n",
    "                image = Image.open(io.BytesIO(image_data['bytes'])).convert(\"RGB\")\n",
    "            elif isinstance(image_data, Image.Image):\n",
    "                image = image_data.convert(\"RGB\")\n",
    "            else:\n",
    "                continue # Skip unknown type\n",
    "            \n",
    "            images_to_process.append(image)\n",
    "        except Exception:\n",
    "            continue # Skip corrupt images\n",
    "            \n",
    "    # 2. Process all images at once\n",
    "    # We move the inputs to the same device as the model\n",
    "    inputs = processor(images=images_to_process, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    # 3. Generate predictions\n",
    "    generated_ids = model.generate(**inputs, max_length=64)\n",
    "    \n",
    "    # 4. Decode predictions\n",
    "    pred_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # 5. Add predictions to the batch\n",
    "    batch[\"predicted_text\"] = pred_text\n",
    "    return batch\n",
    "\n",
    "print(\"Evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64318ebb-15ec-4025-a733-391230229e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on 1000 samples (Batch Size: 8)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2170d8f05d4f412ea126d87c29ddc93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set a safe batch size for your local machine\n",
    "# If you get a memory error, lower this to 4 or 1.\n",
    "EVAL_BATCH_SIZE = 8 \n",
    "\n",
    "print(f\"Running evaluation on {len(test_dataset)} samples (Batch Size: {EVAL_BATCH_SIZE})...\")\n",
    "\n",
    "# This applies our 'predict_batch' function to the entire dataset\n",
    "results_dataset = test_dataset.map(\n",
    "    predict_batch,\n",
    "    batched=True,\n",
    "    batch_size=EVAL_BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(\"...Evaluation complete.\")\n",
    "\n",
    "# Extract the final lists for calculation\n",
    "ground_truth_labels = results_dataset[TEXT_LABEL_COLUMN]\n",
    "model_predictions = results_dataset[\"predicted_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67869bc3-9790-4ba3-b7bc-b8fa8e4fe4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ocr_venv)",
   "language": "python",
   "name": "ocr_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
